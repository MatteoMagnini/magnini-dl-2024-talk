% !TeX spellcheck = en_GB
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{default}}
%
\documentclass[presentation]{beamer}\mode<presentation>{\usetheme{blackAMSBolognaFC}}
%\documentclass[handout]{beamer}\mode<handout>{\usetheme{AMSBolognaFC}}
% \setbeamertemplate{bibliography item}{\insertbiblabel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage[english]{babel}
\usepackage[utf8]{inputenc}
%
\usepackage{magnini-dl-2024-talk}
\usepackage{graphicx}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[Actively Learning from LLMs]{
    % same title of the presented paper
    \textbf{
        Actively Learning Ontologies from LLMs:
        \\
        First Results
    }
}
%
% \subtitle{Extended Abstract}
%
% same authors order of the presented paper
\author[Magnini et al.]{
	\emph{Matteo Magnini}$^{*}$ % empth the presenting author
	\and 
	Ana Ozaki$^{\dagger \ddagger}$
	\\
	Riccardo Squarcialupi$^{*}$
}
%
\institute[UniBo, UiO, UiB]{
    $^{*}$Department of Computer Science and Engineering
    \\
    \textsc{Alma Mater Studiorum} -- University of Bologna
    \\
    \texttt{
        \emph{matteo.magnini}@unibo.it, riccard.squarcialupi@studio.unibo.it
    }
    \vspace{.3cm}
    \\
    $^{\dagger}$Department of Informatics -- University of Oslo
    \\
    \texttt{anaoz@uio.no}
    \vspace{.3cm}
    \\
    $^{\dagger}$Department of Informatics -- University of Bergen
}
%
\date[DL, 2024]{
	International Workshop on Description Logics
	\\
	June 20th, 2024, Bergen (Norway)
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%\AtBeginSection[]
%{
%%\\\\\\\\\\\\\\\\\\\\\
%\begin{frame}<beamer>[c,noframenumbering]
%\frametitle{Next in Line\ldots}
%\tableofcontents[sectionstyle=show/shaded,subsectionstyle=hide]
%\end{frame}
%%\\\\\\\\\\\\\\\\\\\\\
%}
%\AtBeginSubsection[]
%{
%%\\\\\\\\\\\\\\\\\\\\\
%\begin{frame}<beamer>[shrink,noframenumbering]
%    \frametitle{Focus on\ldots}
%	\mbox{~}
%	\tableofcontents[currentsubsection,sectionstyle=shaded,subsectionstyle=show/shaded]
%	\mbox{~}
%\end{frame}
%%\\\\\\\\\\\\\\\\\\\\\
%}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%\\\\\\\\\\\\\\\\\\\\\
\frame{\titlepage}
%\\\\\\\\\\\\\\\\\\\\\

%===============================================================================
\section{Vision \& Context}
%===============================================================================

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[c]{Context}
    
    % Actively Learning
    % Ontologies
    % Membership queries
    % LLMs

    \begin{itemize}
        \item \emph{Actively Learning} $\rightarrow$ a learner attempts to learn some kind of knowledge by posing questions to a teacher.
        \vspace{0.1cm}
        \item \emph{Ontologies} $\rightarrow$ we consider the case in which the knowledge is expressed as an \EL~ontology.
        \vspace{0.1cm}
        \item \emph{Membership queries} $\rightarrow$ the learner can ask the teacher whether a given axiom belongs to the target ontology.
    \end{itemize}
    \vfill
    \begin{figure}
        \includegraphics[width=0.6\textwidth]{figures/membership_queries_examples}
        \hspace{3cm}
    \end{figure}

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[c]{Vision}
    % LLMs as teachers
    % Why? Because they have been trained on large amounts of data of many domains
    % Challenges:
    % - input format
    % - handling the response
    % - correctness and logical consistency of the answers

    We want to use \emph{large language models} (LLMs) as teachers.
    %
    LLMs have been trained on large amounts of data from many domains, and we want to exploit this underlying knowledge.
    %
    \vfill
    %
    Challenges:
    %
    \begin{itemize}
        \item \emph{input format}
        \\
        \quad $\rightarrow$ we used Manchester OWL syntax.
        %
        \item \emph{handling the response}
        \\
        \quad $\rightarrow$ mitigation strategies and parsing.
        %
        \item \emph{correctness and logical consistency of the answers}
        \\
        \quad $\rightarrow$ logical closure.
        %
    \end{itemize}

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%===============================================================================
\section{Experiments \& Results}
%===============================================================================

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[c]{Experiments}

    % 5 EL ontologies from the ExactLearner work
    % 5 LLMs: GPT-3, mistral, mixtral, llama2 7b, llama2 13b
    % 3 different experiments:
    % - check that LLMs can answer axioms of the ontologies
    % - same check but on the entailed axioms (logical closure is finite!)
    % - active learning

    We conducted experiments with:
    \vfill
    %
    \begin{itemize}
        \item \emph{5 \EL~ontologies} $\rightarrow$ Animals, Cell, Football, Generation and University (from the ExactLearner work).
        %
        \vfill
        \item \emph{5 LLMs} $\rightarrow$ GPT 3.5 Turbo, mistral 7b, mixtral 47b, llama2 7b, llama2 13b.
        %
        \vfill
        \item \emph{3 different experiments}:
        \begin{itemize}
            \item \quad check that LLMs can answer axioms of the ontologies.
            \item \quad same check but on the entailed axioms
            \\\quad (logical closure is finite!).
            \item \quad active learning with a trivial learning algorithm.
        \end{itemize}
        \vfill
    \end{itemize}

\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[c]{Results}

    % What did we find?
    % - LLMs can answer axioms of the ontologies
    % - LLMs can answer entailed axioms but we measure some logical inconsistencies
    % - LLMs can be used for active learning. There is statistical evidence that the answers of the LLMs (in particular GPT 3.5 Turbo, Mistral and Mixtral) correlate with the knowledge in the ontologies.

    What did we find?
    \vfill
    %
    \begin{itemize}
        \item \emph{LLMs can answer axioms of the ontologies}.
        %
        \vfill
        \item \emph{LLMs can answer entailed axioms} but we measure some logical inconsistencies.
        %
        \vfill
        \item \emph{LLMs can be used for active learning}
        \\
        $\rightarrow$ there is statistical evidence that the answers of the LLMs (in particular GPT 3.5 Turbo, Mistral and Mixtral) correlate with the knowledge in the ontologies.
    \end{itemize}

\end{frame}

%===============================================================================
\section*{}
%===============================================================================
\frame{\titlepage}

%===============================================================================
\section*{\bibname}
%===============================================================================

\nocite{*}
\setbeamertemplate{page number in head/foot}{}
%\\\\\\\\\\\\\\\\\\\\\
\begin{frame}[t,allowframebreaks,noframenumbering]\frametitle{\refname}
% \begin{frame}[c]\frametitle{\refname}
	\footnotesize
%	\scriptsize
    \bibliographystyle{apalike-AMS}
    % \bibliographystyle{plain}
	\bibliography{magnini-dl-2024-talk}
\end{frame}
%\\\\\\\\\\\\\\\\\\\\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\end{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
